{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d793163",
   "metadata": {},
   "source": [
    "\n",
    "### The estimation of the MLE is based on the material from Quantecon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd94c829",
   "metadata": {},
   "source": [
    "First, we need the following imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4078d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 5)  #set default figure size\n",
    "import numpy as np\n",
    "from numpy import exp\n",
    "from scipy.special import factorial\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import Poisson\n",
    "from statsmodels.api import Probit\n",
    "from statsmodels.api import Logit\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from statsmodels.iolib.summary2 import summary_col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40d5d57",
   "metadata": {},
   "source": [
    "Consider the probit model where the dependent variable ($Y$) is binary, and the independent variables are given by the vector $X$. \n",
    "In addition, assume that $Pr(Y=1|X)= Φ(X^T β)$ where $Φ$ is the CDF of the standard normal distribution. \n",
    "\n",
    "The objective is to maximize the likelihood function over the parameters to find the Maximum Likelihood Estimator (MLE). \n",
    "To find the MLE estimator we maximize the next Log-Likelihood function:\n",
    "\n",
    "$$\n",
    "\\ln L(\\beta \\mid X, Y)=\\sum_{i=1}^n\\left[y_i \\ln \\Phi\\left(x_i^{\\prime} \\beta\\right)+\\left(1-y_i\\right) \\ln \\left(1-\\Phi\\left(x_i^{\\prime} \\beta\\right)\\right)\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acde932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Log-Likelihood Function \n",
    "\n",
    "def LogLikeProbit(betas, y, x):\n",
    "    \"\"\"\n",
    "    Probit Log Likelihood function\n",
    "    Very slow naive Python version\n",
    "    Input:\n",
    "        betas is a np.array of parameters\n",
    "        y is a one dimensional np.array of endogenous data\n",
    "        x is a 2 dimensional np.array of exogenous data\n",
    "            First vertical column of X is assumed to be constant term,\n",
    "            corresponding to betas[0]\n",
    "    returns:\n",
    "        negative of log likehood value (scalar)\n",
    "    \"\"\"\n",
    "    result = 0\n",
    "    #Sum operation\n",
    "    for i in range(0, len(y)):\n",
    "        #Get X'_i * Beta value\n",
    "        xb = np.dot(x[i], betas)\n",
    "        \n",
    "        #compute both binary probabilities from xb     \n",
    "        #Add to total log likelihood\n",
    "        llf = y[i]*np.log(norm.cdf(xb)) + (1-y[i])*np.log(1 - norm.cdf(xb))\n",
    "        result += llf\n",
    "    return -result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "241e1e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit    gre   gpa  rank\n",
       "0      0.0  380.0  3.61   3.0\n",
       "1      1.0  660.0  3.67   3.0\n",
       "2      1.0  800.0  4.00   1.0\n",
       "3      1.0  640.0  3.19   4.0\n",
       "4      0.0  520.0  2.93   4.0\n",
       "..     ...    ...   ...   ...\n",
       "395    0.0  620.0  4.00   2.0\n",
       "396    0.0  560.0  3.04   3.0\n",
       "397    0.0  460.0  2.63   2.0\n",
       "398    0.0  700.0  3.65   2.0\n",
       "399    0.0  600.0  3.89   3.0\n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "#ACTUAL DATA\n",
    "#####################\n",
    "df =pd.read_stata('C:/Users/USUARIO/Dropbox/PHD/CERGE_EI/2nd year/Microeconometrics I/MLE_GMM_SME_MSM/MLE_GMM_SME_MSM/admission.dta')  \n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2bdb6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      380.0\n",
       "1      660.0\n",
       "2      800.0\n",
       "3      640.0\n",
       "4      520.0\n",
       "       ...  \n",
       "395    620.0\n",
       "396    560.0\n",
       "397    460.0\n",
       "398    700.0\n",
       "399    600.0\n",
       "Name: gre, Length: 400, dtype: float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get latent LHS variable\n",
    "y = df.admit\n",
    "n = len(y)\n",
    "\n",
    "#prepend vector of ones to RHS variables matrix\n",
    "#for constant term\n",
    "const = np.ones(n)\n",
    "x = np.column_stack((const, df.gre))\n",
    "\n",
    "x_1 = df.gre\n",
    "\n",
    "x\n",
    "\n",
    "x_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "039dbfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#sample size\\nn = 1000\\n\\n#random generators\\nz1 = np.random.randn(n)\\nz2 = np.random.randn(n)\\n\\n#create artificial exogenous variables \\nx1 = 0.8*z1 + 0.2*z2\\nx2 = 0.2*z1 + 0.8*z2\\n#create error term\\nu = 2*np.random.randn(n)\\n\\n#create endogenous variable from x1, x2 and u\\nystar = 0.5 + 0.75*x1 - 0.75*x2 + u\\n\\n#create latent binary variable from ystar\\ndef create_dummy(data, cutoff):\\n    result = np.zeros(len(data))\\n    for i in range(0, len(data)):\\n        if data[i] >= cutoff:\\n            result[i] = 1\\n        else:\\n            result[i] = 0\\n    return result\\n\\n#get latent LHS variable\\ny = create_dummy(ystar, 0.5)\\n\\n#prepend vector of ones to RHS variables matrix\\n#for constant term\\nconst = np.ones(n)\\nx = np.column_stack((const, np.column_stack((x1, x2))))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "#ARTIFICIAL DATA\n",
    "######################\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#sample size\n",
    "n = 1000\n",
    "\n",
    "#random generators\n",
    "z1 = np.random.randn(n)\n",
    "z2 = np.random.randn(n)\n",
    "\n",
    "#create artificial exogenous variables \n",
    "x1 = 0.8*z1 + 0.2*z2\n",
    "x2 = 0.2*z1 + 0.8*z2\n",
    "#create error term\n",
    "u = 2*np.random.randn(n)\n",
    "\n",
    "#create endogenous variable from x1, x2 and u\n",
    "ystar = 0.5 + 0.75*x1 - 0.75*x2 + u\n",
    "\n",
    "#create latent binary variable from ystar\n",
    "def create_dummy(data, cutoff):\n",
    "    result = np.zeros(len(data))\n",
    "    for i in range(0, len(data)):\n",
    "        if data[i] >= cutoff:\n",
    "            result[i] = 1\n",
    "        else:\n",
    "            result[i] = 0\n",
    "    return result\n",
    "\n",
    "#get latent LHS variable\n",
    "y = create_dummy(ystar, 0.5)\n",
    "\n",
    "#prepend vector of ones to RHS variables matrix\n",
    "#for constant term\n",
    "const = np.ones(n)\n",
    "x = np.column_stack((const, np.column_stack((x1, x2))))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4fd5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31e4037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.76821242,  0.00217499])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create beta hat vector to maximize on\n",
    "#will store the values of maximum likelihood beta parameters\n",
    "#Arbitrarily initialized to all zeros\n",
    "bhat = np.zeros(len(x[0]))\n",
    "\n",
    "#unvectorized MLE estimation\n",
    "probit_est = minimize(LogLikeProbit, bhat, args=(y,x), method='nelder-mead')\n",
    "\n",
    "#print vector of maximized betahats\n",
    "probit_est['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4056644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta Hats:  [-1.76821242  0.00217499]\n",
      "SE:  [0.35917796 0.00059006]\n",
      "t stat:  [-4.92294244  3.68602656]\n",
      "P value:  [9.96900476e-07 2.40032153e-04]\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.tools.numdiff as smt\n",
    "import scipy as sc\n",
    "\n",
    "#Get inverse hessian for Cramer Rao lower bound\n",
    "b_estimates = probit_est['x']\n",
    "Hessian = smt.approx_hess3(b_estimates, LogLikeProbit, args=(y,x))\n",
    "invHessian = np.linalg.inv(Hessian)\n",
    "\n",
    "#Standard Errors from C-R LB\n",
    "#from diagonal elements of invHessian\n",
    "SE = np.zeros(len(invHessian))\n",
    "for i in range(0, len(invHessian)):\n",
    "    SE[i] =  np.sqrt(invHessian[i,i])\n",
    "    \n",
    "#t and p values\n",
    "t_statistics = (b_estimates/SE)\n",
    "pval = (sc.stats.t.sf(np.abs(t_statistics), 999)*2)\n",
    "\n",
    "print(\"Beta Hats: \", b_estimates)\n",
    "print(\"SE: \", SE)\n",
    "print(\"t stat: \", t_statistics)\n",
    "print(\"P value: \", pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c4cd076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.607481\n",
      "         Iterations 5\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  admit   No. Observations:                  400\n",
      "Model:                         Probit   Df Residuals:                      398\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Mon, 31 Oct 2022   Pseudo R-squ.:                 0.02798\n",
      "Time:                        18:38:10   Log-Likelihood:                -242.99\n",
      "converged:                       True   LL-Null:                       -249.99\n",
      "Covariance Type:            nonrobust   LLR p-value:                 0.0001836\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.7682      0.359     -4.923      0.000      -2.472      -1.064\n",
      "x1             0.0022      0.001      3.686      0.000       0.001       0.003\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#Using other routine\n",
    "stats_probit = Probit(y, x).fit()\n",
    "print(stats_probit.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f974109f",
   "metadata": {},
   "source": [
    "### Maximum Simulated Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f5c7a1",
   "metadata": {},
   "source": [
    "The subsimulator is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\widetilde{f}_{Y_i, X_i \\mid U_s}\\left(y_i, x_i \\mid u_s ; \\beta_0, \\beta_1, \\sigma^2\\right)=\\Lambda\\left[\\beta_0+\\left(\\beta_1+\\sigma u_s\\right) x_i\\right]^{y_i}\\left\\{1-\\Lambda\\left[\\beta_0+\\left(\\beta_1+\\sigma u_s\\right) x_i\\right]\\right\\}^{1-y_i}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "471a4635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.884704\n",
       "1     -0.278504\n",
       "2      0.015564\n",
       "3     -0.304401\n",
       "4     -0.632713\n",
       "         ...   \n",
       "395   -0.474591\n",
       "396   -0.532811\n",
       "397   -0.853740\n",
       "398   -0.381661\n",
       "399   -0.454896\n",
       "Name: gre, Length: 400, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_s = np.random.normal(loc=0, scale=1, size=n)\n",
    "\n",
    "θ = -1.7682 + (0.0022 + 0.0001*u_s)*x_1\n",
    "θ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5db7a017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_subsim = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5b605a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.66897527 -0.84288051 -0.79410343 -0.84407169 -0.71349652 -0.79914119\n",
      " -0.85421581 -0.68531081 -0.88807393 -0.76792278 -0.80086317 -0.69325846\n",
      " -0.79859888 -0.7667672  -0.90044784 -0.71118391 -0.79192553 -0.68525917\n",
      " -0.7996591  -0.90944862 -0.71211663 -0.86466836 -0.73515134 -0.75759168\n",
      " -0.83915114 -0.73591316 -0.88299974 -0.9239622  -0.7863243  -0.70425646\n",
      " -0.71554229 -0.7848563  -0.73435514 -0.75488567 -0.68320911 -0.68729601\n",
      " -0.73147571 -0.71653141 -0.88091714 -0.91997492 -0.72820202 -0.9013167\n",
      " -0.90753343 -0.69677976 -0.76458192 -0.9605658  -0.9308632  -0.70626311\n",
      " -0.70013043 -0.68416774 -0.74804871 -0.6876705  -0.77950617 -0.82819935\n",
      " -0.75230521 -0.84273696 -0.71718471 -0.67129617 -0.67890072 -0.73813172\n",
      " -0.87405603 -0.71953383 -0.74734127 -0.85031656 -0.71894554 -0.73367058\n",
      " -0.77746184 -0.74386375 -0.72883494 -0.79891887 -0.7467761  -0.65341446\n",
      " -0.70271931 -0.73386988 -0.77246676 -0.77070098 -0.72014527 -0.78664996\n",
      " -0.71869313 -0.88552883 -0.76447995 -0.75223072 -0.7193045  -0.70371892\n",
      " -0.93634264 -0.71807792 -0.73426146 -0.73602998 -0.76405387 -0.84897672\n",
      " -0.76285235 -0.8563326  -0.79906533 -0.7403807  -0.85455166 -0.75405568\n",
      " -0.75002528 -0.71046263 -0.76130519 -0.69018493 -0.67801518 -0.7239746\n",
      " -0.68695909 -0.72741896 -0.83944807 -0.82797442 -0.8447909  -0.69472449\n",
      " -0.68977068 -0.70789521 -0.7579728  -0.69223571 -0.67922228 -0.72813864\n",
      " -0.77578616 -0.73890299 -0.97524821 -0.76398984 -0.78965767 -0.66729232\n",
      " -0.90823771 -0.96698437 -0.71316671 -0.69882949 -0.77319772 -0.71639994\n",
      " -0.85880673 -0.77802927 -0.73215003 -0.71610415 -0.84680847 -0.73922564\n",
      " -0.72681247 -0.7108823  -0.72599905 -0.71526248 -0.71152768 -0.76532936\n",
      " -0.7344562  -0.86795248 -0.74605724 -0.88934748 -0.73936087 -0.71884992\n",
      " -0.73267402 -0.67099429 -0.71499172 -0.72124315 -0.9089591  -0.77823229\n",
      " -0.80787735 -0.68728435 -0.85783826 -0.72148822 -0.74401841 -0.88971808\n",
      " -0.72046102 -0.9026824  -0.75295735 -0.76169829 -0.73339734 -0.74512434\n",
      " -0.87645615 -0.7152586  -0.72390583 -0.76891013 -0.68702692 -0.77248452\n",
      " -0.70746469 -0.73601209 -0.67658335 -0.7108534  -0.75420216 -0.82046469\n",
      " -0.71689606 -0.89074506 -0.70785317 -0.85270455 -0.74289518 -0.6783758\n",
      " -0.74371224 -0.70620836 -0.76315709 -0.92501036 -0.70223989 -0.79959818\n",
      " -0.71753566 -0.73240559 -0.72737793 -0.71442039 -0.85432168 -0.79964242\n",
      " -0.74301412 -0.69796296 -0.89741877 -0.72135763 -0.74899507 -0.97309181\n",
      " -0.73057706 -0.73293262 -0.79931886 -0.9333413  -0.83945339 -0.7035783\n",
      " -0.8492806  -0.83159514 -0.77715024 -0.86712084 -0.71432113 -0.73296266\n",
      " -0.77713411 -0.73151685 -0.70272192 -0.7416099  -0.90474713 -0.86449074\n",
      " -0.65594344 -0.97501211 -0.70896367 -0.90891464 -0.7081522  -0.75931849\n",
      " -0.93922643 -0.79895364 -0.79919129 -0.81055347 -0.74077023 -0.73207716\n",
      " -0.7064503  -0.83121166 -0.73874689 -0.73378135 -0.67613097 -0.68903114\n",
      " -0.81899525 -0.73611901 -0.89286058 -0.70058393 -0.71087018 -0.76321822\n",
      " -0.70940639 -0.96262924 -0.86152968 -0.73620044 -0.72078078 -0.79967387\n",
      " -0.75713679 -0.68459652 -0.75805611 -0.74516976 -0.74800295 -0.73468507\n",
      " -0.95275146 -0.90564858 -0.82038197 -0.74017383 -0.94408554 -0.89357613\n",
      " -0.70745192 -0.74576905 -0.75761545 -0.69284494 -0.96681496 -0.91524915\n",
      " -0.9024166  -0.677889   -0.72241343 -0.90233691 -0.83669409 -0.71287667\n",
      " -0.87474681 -0.71741567 -0.86457388 -0.75173726 -0.71089715 -0.88916614\n",
      " -0.70280476 -0.86879374 -0.87718255 -0.91441976 -0.75171576 -0.67805662\n",
      " -0.75412182 -0.70789139 -0.96369299 -0.74855314 -0.85852237 -0.85669754\n",
      " -0.79927973 -0.69549934 -0.88379089 -0.79893375 -0.75915233 -0.79930651\n",
      " -0.70229003 -0.70533957 -0.72095748 -0.69962155 -0.70703523 -0.77208255\n",
      " -0.7404243  -0.89377612 -0.98016776 -0.80329679 -0.64374022 -0.72576099\n",
      " -0.87219076 -0.71794537 -0.71992063 -0.69252778 -0.72461497 -0.75106011\n",
      " -0.75335263 -0.94466887 -0.72285149 -1.04838429 -1.03019813 -0.74179422\n",
      " -0.93912813 -0.72349573 -0.69842024 -0.70924614 -0.70934997 -0.68146737\n",
      " -0.70606255 -0.75882228 -0.75734808 -0.86401589 -0.71709866 -0.71690466\n",
      " -0.7769874  -0.753189   -0.67350269 -0.72549701 -0.91779983 -0.84392328\n",
      " -0.70557645 -0.74509069 -0.71726372 -0.88024524 -0.70055026 -0.88275848\n",
      " -0.71654106 -0.7327834  -0.71868012 -0.70434385 -0.73616654 -0.72854938\n",
      " -0.69090814 -0.73708924 -0.79740934 -0.73742492 -0.9203175  -0.76568964\n",
      " -0.89091863 -0.86800437 -0.76359267 -0.77230134 -0.89443989 -0.77633672\n",
      " -0.89956013 -0.90375447 -0.75854604 -0.69739962 -0.88500284 -0.69989125\n",
      " -0.70440176 -0.73616625 -0.73452038 -0.79909981 -0.87356726 -0.82656144\n",
      " -0.85320801 -0.89334607 -0.71537392 -0.72256756 -0.74013201 -0.82654566\n",
      " -0.74125419 -0.70414064 -0.76380642 -0.94188215 -0.70428263 -0.74975246\n",
      " -0.93440697 -0.69260251 -0.82947099 -0.72970048 -0.74674701 -0.74065609\n",
      " -0.8282734  -0.89465221 -0.90030618 -0.8608071  -0.94970204 -0.7453253\n",
      " -0.72257159 -0.71542304 -0.77161449 -0.73460661]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "for j in range(S):\n",
    "    θ = -1.7682 + (0.0022 + 0.0001*u_s[j])*x_1[1]\n",
    "    Λ = 1/(1+ np.exp(-θ))\n",
    "    subsim = y[1]*np.log(Λ)+(1-y[1])*np.log(1-Λ)  \n",
    "    vector_subsim.append(subsim)\n",
    "sl = np.mean(vector_subsim)\n",
    "print(sl)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "78c58dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.345599\n",
       "1     -0.842064\n",
       "2     -0.685396\n",
       "3     -0.856886\n",
       "4     -0.426018\n",
       "         ...   \n",
       "395   -0.483746\n",
       "396   -0.461816\n",
       "397   -0.354747\n",
       "398   -0.520416\n",
       "399   -0.491345\n",
       "Length: 400, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213efb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5303cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the number of simulations\n",
    "S = 10\n",
    "\n",
    "#Define the Random Parameter Mixed Simulated Likelihood Function.\n",
    "def mslf(S, β_0, β_1, σ, Y, X):\n",
    "  #Set up the major variables that will be used to created a likelihood  \n",
    "    Y = Y\n",
    "    X = X\n",
    "    \n",
    "  #set of parameters we are hoping to find the MSL estimates of.\n",
    "    β_0 = β_0\n",
    "    β_1 = β_1  \n",
    "    σ = σ   \n",
    "    \n",
    "    sim_avg_f=0\n",
    "\n",
    "  #Simulation\n",
    "    vector_subsim = []\n",
    "    vector_sim = []\n",
    "    #Establish the seed\n",
    "    np.random.seed(1234)\n",
    "    ##Take a random sample for u_i from Hu(u_i) (Cumulative distribution of u_i that is assumed normal)\n",
    "    u_s = np.random.normal(loc=0, scale=1, size=n)\n",
    "    #Let's create the loop to generate the mslf\n",
    "    #np.seterr(divide = 'ignore')\n",
    "    for i in range(n):\n",
    "        for j in range(S):\n",
    "            θ = β_0 + (β_1 + σ*u_s[j])*X[i]\n",
    "            Λ = 1/(1+ np.exp(-θ))\n",
    "            subsim = Y[i]*np.log(Λ)+(1-Y[i])*np.log(1-Λ)  \n",
    "            vector_subsim.append(subsim)\n",
    "        sl[i] = np.mean(vector_subsim)\n",
    "        vector_sim.append(sl[i])\n",
    "        \n",
    "    print(len(vector_sim))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4b988277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "mslf(S, -1.7682, 0.0022, 0.0001, y, x_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e62a43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ddf96dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed462d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "'''\n",
    "mslf <- function(param){\n",
    "  #Set up the major variables that will be used to created a likelihood\n",
    "  choice<-Data$preference_liking\n",
    "  endowment<-Data$InitialGood_Stage1\n",
    "  \n",
    "  #set of parameters we are hoping to find the MSL estimates of.\n",
    "  lambda_m<-param[1]\n",
    "  u1<-param[2]\n",
    "  u2<-param[3]\n",
    "  u3<-param[4]\n",
    "  u4<-param[5]\n",
    "  delt<-param[6]\n",
    "  sd<-exp(param[7])\n",
    "  \n",
    "\n",
    "  sim_avg_f=0\n",
    "  \n",
    "  set.seed(10101)\n",
    "  \n",
    "  #create the for loop over which we generate the simulated likelihood function\n",
    "  for(i in 1:num_draws){\n",
    "    #first, generate a set of random normal variables for each individual\n",
    "    #This will represent the underlying (unobserved) heterogeneity in our random parameter model.\n",
    "    unobserved_noise<-rnorm(nrow(Data), 0, 1)\n",
    "    \n",
    "    #Draw lambda value for an individual, sampling from the mean value (lambda_temp) with noise e*sd.\n",
    "    lambda<-lambda_m+unobserved_noise*sd\n",
    "    \n",
    "    #Given individual context, generate the KR structural utilities.\n",
    "    #Good a represents the endowment, so we compute U(a|a).\n",
    "    kr_utils_good_a=u1*(endowment==1)+u2*(endowment==2)+u3*(endowment==3)+u4*(endowment==4)\n",
    "    #Good b represents the alternative good, so we compute U(b|a)\n",
    "    kr_utils_good_b=(2*u2-lambda*u1)*(endowment==1)+(2*u1-lambda*u2)*(endowment==2)+\n",
    "                    (2*u4-lambda*u3)*(endowment==3)+(2*u3-lambda*u4)*(endowment==4)\n",
    "    \n",
    "    #Construct the likelihood at the given draw\n",
    "    sim_f=(exp(kr_utils_good_a)/(exp(kr_utils_good_a)+exp(kr_utils_good_b+delt)))*(choice==1)+\n",
    "          (exp(kr_utils_good_b)/(exp(kr_utils_good_b)+exp(kr_utils_good_a+delt)))*(choice==-1)+\n",
    "        (1- (exp(kr_utils_good_b)/(exp(kr_utils_good_b)+exp(kr_utils_good_a+delt)))-\n",
    "           (exp(kr_utils_good_a)/(exp(kr_utils_good_a)+exp(kr_utils_good_b+delt))) )*(choice==0)\n",
    "        \n",
    "    sim_avg_f = sim_avg_f + sim_f/num_draws\n",
    "\n",
    "  }\n",
    "  log(sim_avg_f)\n",
    "} \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
